#!/usr/bin/env python3

# -*- coding: utf-8 -*-
"""
Finds ThorSync directories corresponding to ThorImage directories
by looking for filenames or a descriptions of pins used in each
presentation, and matching that to the pins the Arduino says it 
uses, decoded from the ThorSync data.

Need to have pin signalled as in my OlfStimDelivery.ino script and 
follow my practice of copying something containing either the 
filename or the full pins to be presented in to the Notes field
in the ThorImage Capture settings.

Created on Wed Mar 15 15:02:09 2017

@author: Tom O'Connell
"""

from __future__ import print_function

import os
import xml.etree.ElementTree as etree
import ast
import re
import pickle
import datetime
import tom.odors

import h5py
import numpy as np

# TODO move below functions into shared util between this and analysis

def get_fly_id(directory_name):
    return '_'.join(os.path.split(directory_name)[-1].split('_')[:2])

def get_session_id(directory_name):
    return '_'.join(os.path.split(directory_name)[-1].split('_')[2])

def get_exptime(thorimage_dir):
    expxml = os.path.join(thorimage_dir, 'Experiment.xml')
    return int(etree.parse(expxml).getroot().find('Date').attrib['uTime'])


def get_synctime(thorsync_dir, time=os.path.getmtime):
    syncxml = os.path.join(thorsync_dir, 'ThorRealTimeDataSettings.xml')
    return time(syncxml)


def get_readable_exptime(thorimage_dir):
    expxml = os.path.join(thorimage_dir, 'Experiment.xml')
    return etree.parse(expxml).getroot().find('Date').attrib['date']


def readable_timestamp(unix_timestamp):
    return datetime.datetime.fromtimestamp(unix_timestamp)


# warn if has SyncData in name but fails this?
def is_thorsync_dir(d):
    if not os.path.isdir(d):
        return False
    
    files = {f for f in os.listdir(d)}

    have_settings = False
    have_h5 = False
    for f in files:
        # checking for substring
        if 'ThorRealTimeDataSettings.xml' in f:
            have_settings = True
        if '.h5':
            have_h5 = True
            
    return have_h5 and have_settings


def is_thorimage_dir(d):
    if not os.path.isdir(d):
        return False
    
    files = {f for f in os.listdir(d)}

    have_xml = False
    tifs = 0
    for f in files:
        if 'Experiment.xml' in f:
            have_xml = True
        elif '.tif' in f:
            tifs += 1

    if have_xml and tifs > 1:
        return True
    else:
        return False


# TODO actually check how OME tifs are indexed?
def is_anatomical_stack(d):
    return 'anat' in d

make_changes = True
ignore_thorsync = True

# in here should be a directory called 'stimuli'
# which should have pickle files generated by *_odor_randomizer.py
'''
stimuli_base_dir = 'D:/Hong/Tom/stimuli'
thorimage_dir = 'D:/Hong/Tom/flies'
thorsync_dir = 'D:/Hong/Tom/flies'
'''
stimuli_base_dir = '/media/threeA/Tom/stimuli'
thorimage_dir = '/media/threeA/Tom/flies'
thorsync_dir = '/media/threeA/Tom/flies'

sync_dirs = [os.path.join(thorsync_dir,d) for d in os.listdir(thorsync_dir)]
sync_dirs = sorted([d for d in sync_dirs if is_thorsync_dir(d)], key=get_synctime)

#ordered_sync_dirs = [x for x,y in sorted([(d, get_synctime(d)) \
#        for d in sync_dirs], key=lambda x: x[1])]

valid_fly_ids = re.compile(r'(\d{6}_\d{2}(?:e|c)?_)')

image_dirs = [os.path.join(thorimage_dir,d) for d in os.listdir(thorimage_dir)]
image_dirs =  [d for d in image_dirs \
        if os.path.isdir(d) and valid_fly_ids.search(d)]

# TODO flag to override assertion errors or to ask y/n instead
# TODO add colors to warnings and green if things pass

# doesn't actually check for the ../../stimuli/ prefix
# assumes in is in stimuli_base_dir above
stimfile_pattern = re.compile(r'(\d{4}-\d{2}-\d{2}_\d{6}\.p)')

# are angle / square brackets special chars?
#pinlist_re = re.compile(r'\[\{(?:\d\d?(?:, )?)+\}(?:, )?\]+')
pinlist_re = re.compile(r'\[(?:\[(?:\{(?:\d\d?(?:, )?)+\}(?:, )?)+\](?:, )?)+\]')
pin_odor_port_re = re.compile(r'(\d\d?) -> (.* 1e-?\d\d?) -> ([A-Z])')

fly2pl = dict()
fly2ac = dict()
fly2stim = dict()

fly_ids = []

stimfile2imgdir = dict()
without_stimfile = []

without_thorsync = []

sync_image_mismatch_cutoff = 2 # seconds

# TODO specifically check that all things with same session ID
# seem to be using the same stimulus panel

for img_dir in image_dirs:
    fly_id = get_fly_id(img_dir)
    print(img_dir)
    
    # TODO do something with their ThorSync dirs, to clean things up
    # but can't decode obviously
    # this is how i name the anatomical stacks
    if is_anatomical_stack(img_dir):
        continue
    
    fly_ids.append(fly_id)

    if not ignore_thorsync:
        in_img_dir = [os.path.join(img_dir,o) for o in os.listdir(img_dir)]
        possible_thorsync_dirs = [d for d in in_img_dir if is_thorsync_dir(d)]

        if len(possible_thorsync_dirs) > 1:
            raise Exception('found too many possible thorsync directories in ' + \
                str(img_dir) + '. should only ever be at most one.')

        elif len(possible_thorsync_dirs) == 1:
            # (in seconds)
            sync_exp_timediff = get_synctime(possible_thorsync_dirs[0]) - get_exptime(img_dir)
            assert abs(sync_exp_timediff) < sync_image_mismatch_cutoff, \
                'nested ThorSync XML file (in ' + \
                possible_thorsync_dirs[0] + ') modified ' + str(sync_exp_timediff) + \
                ' seconds apart from date in ThorImage Experiment.xml'
            
            print('skipping ' + str(img_dir) + ' because found nested ThorSync directory')
            # skip this directory, because it already seems matched
            continue
        
        else:
            without_thorsync.append(img_dir)

    expxml = os.path.join(img_dir, 'Experiment.xml')
    notes = etree.parse(expxml).getroot().find('ExperimentNotes').attrib['text']
    stimfile = stimfile_pattern.search(notes)

    # TODO warn if more than one found?
    
    # TODO unit test
    if stimfile is not None:
        stimfile = stimfile.group(0)
        unplaced_stimfile = os.path.join(stimuli_base_dir, stimfile)
        
        if not os.path.isfile(unplaced_stimfile):
            placed_stimfile = os.path.join(img_dir, stimfile)
            if os.path.isfile(placed_stimfile):
                stimfile = placed_stimfile
            else:
                print(stimfile + ' went missing!')
                stimfile = None
        else:
            stimfile = unplaced_stimfile
            
    if stimfile is not None:
        stimfile2imgdir[stimfile] = img_dir
        
        with open(stimfile, 'rb') as f:
            acs_raw, odor_list_raw = pickle.load(f)
            acs_loaded = tuple(tuple(sorted(l, key=lambda x: x[0])) for l in acs_raw)
            odor2pin_list = [{trip[1]: trip[0] for trip in acs} for acs in acs_loaded]
            # TODO convert odorset list to pinset list
            pl_loaded = tuple(tuple(set(d[o] for o in s) for s in l) \
                              for l, d in zip(odor_list_raw, odor2pin_list))
    else:
        acs_loaded = None
        pl_loaded = None
        
        without_stimfile.append(img_dir)
        
    # TODO check loaded stuff is consistent with everything else (including order?),
    # and if it is, add it to same dict. directly comparable? tuple?
        
    pl_match = pinlist_re.search(notes)
    pl = None
    
    # TODO check loaded information with parsed information
    if pl_match is not None:
        #if pl_loaded is None:
        #    print('order')
        pl = ast.literal_eval(pl_match.group(0))
        pl = tuple(tuple(l) for l in pl)
        
        # IF WE HAVE DATA FOR THIS SPECIFIC SESSION, this checks that it is 
        # apparently consistent with information from flies with the same id
        if fly_id in fly2pl:
            assert pl == fly2pl[fly_id], 'apparently conflicting list of pins' + \
                ' presented across flies with the same id: ' + fly_id
        else:
            fly2pl[fly_id] = pl
            
        # checks consistency with pin order loaded from pickle file
        # currently will only work if full pin order can be parsed from
        # notes in each session
        if pl_loaded is not None:
            assert pl == pl_loaded, 'pin order loaded from stimulus pickle ' + \
                'file is apparently inconsistent with pin order in notes. ' + \
                fly_id
    
    #elif pl_loaded is not None:
    if pl_loaded is not None:
        # check might be unnecessary
        if fly_id in fly2pl:
            assert pl_loaded == fly2pl[fly_id], 'apparently conflicting ' + \
                'list of pins presented across flies with ' + \
                'the same id (one of which was loaded from pickle): ' + fly_id
        else:
            fly2pl[fly_id] = pl_loaded
    
    # assumes connections will be printed out in a consistent order
    # across all files compared here (to check equality of parsed tuples)
    # also assumes that if there are multiple sets of connections printed, 
    # they are separated by the word 'stoppers' somewhere
    
    # will only use first 3.
    all_connections = [pin_odor_port_re.findall(n) for n in notes.split('stoppers')[:3]]
    all_connections = tuple(tuple((int(x[0]), tom.odors.str2pair(x[1]), x[2]) for x in ac) \
                            for ac in all_connections if len(ac) > 0)
    
    # TODO careful. this may break easily
    if len(all_connections) > 1:
        #if acs_loaded is None:
        #    print('connections')

        # IF WE HAVE DATA FOR THIS SPECIFIC SESSION, this checks that it is 
        # apparently consistent with information from flies with the same id
        if fly_id in fly2ac:
            assert all_connections == fly2ac[fly_id], 'apparently conflicting ' + \
                'pin (valve) to odor connections presented across flies with ' + \
                'the same id: ' + fly_id
        else:
            fly2ac[fly_id] = all_connections
            
        # TODO test this section and the below!
        if acs_loaded is not None:
            assert all_connections == acs_loaded, 'connections described in notes ' + \
                'are apparently inconsistent with those in stimulus pickle file ' + \
                fly_id + '\n\nnotes:' + str(all_connections) + '\n\nloaded:' + str(acs_loaded)
                
    # TODO maybe clean this section up? might be redundant
    if acs_loaded is not None:
        # check might be unnecessary
        if fly_id in fly2ac:
            assert acs_loaded == fly2ac[fly_id], 'apparently conflicting ' + \
                'pin (valve) to odor connections presented across flies with ' + \
                'the same id (one of which was loaded from pickle): ' + fly_id
        else:
            fly2ac[fly_id] = acs_loaded

fly_ids = set(fly_ids)
#print('Processing fly IDs:')
#print(fly_ids)

# TODO warn and include list of things we dont have stimulus for at this point
# mappings and pins separately?
    
# could happen by chance with reasonable probability if you have a really
# small odor panel

# TODO write unit tests for these!!!

# TODO but this will happen if something is run twice
# maybe just delete in advance trials that went badly?
# checks the same pin order isn't observed twice in recording
# sessions with different fly_ids (even though not all recordings
# list this)
# would likely indicate a data entry error
for fly in fly2pl:
    copy = dict(fly2pl)
    del copy[fly]
    assert fly2pl.values() != copy.values(), 'possible duplication data entry ' + \
        'error (' + fly + ' and at least one other are involved)'

# checks the same connection pattern isn't observed twice in recording
# sessions with different fly_ids. same reason.
for fly in fly2ac:
    copy = dict(fly2ac)
    del copy[fly]
    assert set(fly2ac.values()) != set(copy.values()), \
        'possible duplication data entry error (' + fly + ' and at least one other are involved)'

assert len(stimfile2imgdir.keys()) == len(stimfile2imgdir.values()), \
    'this should not happen, but dont want to do something dangerous'

'''
# if we have not failed any checks so far, move the stimulus files 
# to their matching ThorImage directories
for sf in stimfile2imgdir:
    dst = stimfile2imgdir[sf]
    assert os.path.isdir(dst)
    # should copy (some?) operating system metadata too
    # TODO prompt first?
    shutil.copy2(sf, dst)
'''

# TODO only print the ones nothing can be found for !!!
# wasn't i doing that before?

# generate correct pin 2 odor mappings from notes in available
# save in ThorImage directory as differently named pickle file
# to be read by analysis software
print('Valve to odor connections and stimulus order pickle file not found for:')
for d in without_stimfile:
    print(d)
print('')

# figure out ordering of sessions, to draw from correct index in list of 
# stimulus dictionaries
dir2session_idx = dict()

for fid in fly_ids:
    # TODO sorted in correct order?
    fid_indexed_dirs = [(i,d) for i,d in \
        enumerate(sorted(image_dirs, key=get_exptime)) \
            if fid in d and not is_anatomical_stack(d)]
    
    # should all be consecutive
    # we don't take flies off and put the same ones back on later
    # after running other flies
    dir_indices = [i for i,d in fid_indexed_dirs]
    min_idx = min(dir_indices)
    max_idx = max(dir_indices)
    # TODO test
    for i in range(min_idx, max_idx + 1):
        assert i in dir_indices, 'directories for fly ' + fid + \
            ' are apparently not consecutive (by date in Experiment.xml)'
    
    fid_dirs = [d for i,d in fid_indexed_dirs]
    idx = 0
    last_session = None
    previous_sessions = set()
    for d in fid_dirs:
        session = get_session_id(d)
        
        if last_session is not None and last_session != session:
            idx += 1
            
            # if the new session has already been seen before,
            # it would suggest something fishy
            assert not session in previous_sessions, 'repeats of ' + \
                'session ' + session + ' apparently not consecutive'
            
                
        dir2session_idx[d] = idx
        
        last_session = session
        previous_sessions.add(session)

# TODO handle cases where we can (possibly only) parse pin list   
for d in image_dirs:
    # maybe handle this once earlier in manner that avoids checking repeatedly?
    if is_anatomical_stack(d):
        continue
    
    fly_id = get_fly_id(d)

    # TODO just prevent it from being added as None
    if fly_id in fly2ac and fly2ac[fly_id] is not None:
        gen_connections = os.path.join(d, 'generated_pin2odor.p')
        
        print('saving valve to odor connections for ' + \
              fly_id + ' to ' + gen_connections)
        #print(dir2session_idx[d])
        
        if make_changes:
            with open(gen_connections, 'wb') as f:
                # TODO prompt first?           
                pickle.dump(fly2ac[fly_id][dir2session_idx[d]], f)

# TODO can i match them up one to one?
#for d in image_dirs:
#    print(get_exptime(d), datetime.datetime.fromtimestamp(os.path.getmtime(d)), d)

if not ignore_thorsync:
    stamped_sync_dirs = [(get_synctime(s), s) for s in sync_dirs]

    to_move = dict()

    if not make_changes:
        print('data directories without ThorSync subdirectories:')

    # TODO include anat as well
    for d in sorted(without_thorsync, key=get_exptime):
        nearest = min(stamped_sync_dirs, key=lambda x: abs(x[0] - get_exptime(d)))
        nearest_thorsync= nearest[1]
            
        if not make_changes:
            print(d)
            print(nearest[0] - get_exptime(d))
            print(nearest_thorsync)
            print('')
        
        '''
        if abs(nearest[0] - get_exptime(d)) > 1:
            print(d)
            print(nearest[0] - get_exptime(d))
            print(nearest_thorsync)
            print('')
        '''
            
        if abs(nearest[0] - get_exptime(d)) < sync_image_mismatch_cutoff:
            to = os.path.join(d, os.path.split(nearest_thorsync)[-1])
            if make_changes:
                os.rename(nearest_thorsync, to)
            to_move[nearest_thorsync] = to
          
    # TODO get rid of common prefix. include shebang line.
    for src in to_move:
        print('mv -nv', src, to_move[src])

"""
for d in sync_dirs:
    # ctime and mtime don't always agree, but almost always do
    '''
    print(get_synctime(d))
    print(get_synctime(d, time=os.path.getctime))
    print(np.isclose(get_synctime(d), get_synctime(d, time=os.path.getctime)))
    '''
    print(readable_timestamp(get_synctime(d)), d)
"""
    
# can mostly ignore this for now because matching SyncData with the anat
# is less important
# and can just move everything else to another directory for now
'''
# clean up ThorSync directories from trials that have no frames
# other indications of a bad run? # indices / sampling rate?
# if it was stopped while frame / something else was still changing?
# / while acquisition trigger was high?
for d in sync_dirs:
    # TODO what was up with directories i saw with multiple h5 files?
    h = h5py.File(os.path.join(d,'Episode001.h5'), 'r')
    # should be the max?
    # TODO why was this not always nested in another (list?)
    print(h['CI']['frame_counter'][-1])
    #max_frame = np.array(h['CI']['frame_counter']).max()
    #print(max_frame)

print(len(sync_dirs))
print(len(without_thorsync))
'''

# for each pickle file, find the ThorSync file that matches that 
# pin presentation order after decoding

# TODO make sure no two SyncData files decode to the same thing
# ALTHOUGH THIS COULD HAPPEN... MAYBE DONT
# TODO if >1 SyncData decode to same thing (and loaded parsed data does too)
# match them up in time and warn
# move matching to imaging directories

# if any imaging directories do not appear to have corresponding
# ThorSync data, there is a serious problem that the user needs
# to address

# move non-matching to orphans
